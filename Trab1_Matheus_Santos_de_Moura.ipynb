{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b4c8ea",
   "metadata": {},
   "source": [
    "# Comparação Experimental de Técnicas de Classificação\n",
    "\n",
    "Este trabalho tem como objetivo realizar uma **comparação experimental** entre um conjunto pré-definido de técnicas de aprendizado e classificação automática aplicadas a um problema de **classificação supervisionada**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58720d99",
   "metadata": {},
   "source": [
    "## Técnicas Utilizadas\n",
    "\n",
    "As seguintes técnicas de aprendizado serão avaliadas:\n",
    "\n",
    "- **Decision Tree (DT)**\n",
    "- **K Nearest Neighbors (KNN)**\n",
    "- **Multi-layer Perceptron (MLP)**\n",
    "- **Random Forest (RF)**\n",
    "- **Heterogeneous Boosting (HB)**\n",
    "\n",
    "## Procedimento Experimental\n",
    "\n",
    "O experimento será conduzido em **3 rodadas** de ciclos aninhados de validação e teste, organizados da seguinte forma:\n",
    "\n",
    "- **Validação interna:** 4 folds\n",
    "- **Teste externo:** 10 folds\n",
    "\n",
    "A seleção de hiperparâmetros será realizada por **busca em grade** (_grid search_) no ciclo interno, com os seguintes valores para cada técnica:\n",
    "\n",
    "### Hiperparâmetros\n",
    "\n",
    "```python\n",
    "# Decision Tree (DT)\n",
    "{\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 15, 25]\n",
    "}\n",
    "\n",
    "# K Nearest Neighbors (KNN)\n",
    "{\n",
    "    'n_neighbors': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# Multi-layer Perceptron (MLP)\n",
    "{\n",
    "    'hidden_layer_sizes': [(100,), (10,)],\n",
    "    'alpha': [0.0001, 0.005],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Random Forest (RF)\n",
    "{\n",
    "    'n_estimators': [5, 10, 15, 25],\n",
    "    'max_depth': [10, None]\n",
    "}\n",
    "\n",
    "# Heterogeneous Boosting (HB)\n",
    "{\n",
    "    'n_estimators': [5, 10, 15, 25, 50]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10de79a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos de classificação\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Validação cruzada e avaliação\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Criação do Heterogeneous Boosting\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb58fb3",
   "metadata": {},
   "source": [
    "# Configurações de exibição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações gerais de visualização\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0dc2b",
   "metadata": {},
   "source": [
    "# Importando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264acf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"jogosLoL2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba45642",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb36c1",
   "metadata": {},
   "source": [
    "**Descartar o identificador da partida** e realizar a **padronização das características numéricas** (normalização).\n",
    "\n",
    "As características que usaremos são os dados pré-jogos, ou seja, as informações disponíveis antes do início da partida, como:\n",
    "\n",
    "- WR (Win-Rate do Time Azul)\n",
    "- KD (Kill-to-Death Ratio do Time Azul)\n",
    "- GPR (Gold Percent Ratio do Time Azul)\n",
    "- GSPD (Average Gold Spent Ratio do Time Azul)\n",
    "- EGR (Early-Game-Rate do Time Azul)\n",
    "- MLR (Mid-Late-Game-Rate do Time Azul)\n",
    "- FB% (First Blood Rate do Time Azul)\n",
    "- FT% (First Blood Rate do Time Azul)\n",
    "- F3T% (First To Three Towers Rate do Time Azul)\n",
    "- HLD% (Harold Rate do Time Azul)\n",
    "- DRG% (Dragon Rate do Time Azul)\n",
    "- BN% (First Blood Rate do Time Azul)\n",
    "- LNE% (Lane Control Rate do Time Azul)\n",
    "- JNG% (Jungle Control Rate do Time Azul)\n",
    "- OPP_WR (Win-Rate do Time Vermelho)\n",
    "- OPP_KD (Kill-to-Death Ratio do Time Vermelho)\n",
    "- OPP_GPR (gold Percent Ratio) do Time Vermelho\n",
    "- OPP_GSPD (Average Gold Spent Ratio do Time Vermelho)\n",
    "- OPP_EGR (Early-Game-Rate do Time Vermelho)\n",
    "- OPP_MLR (Mid-Late-Game-Rate do Time Vermelho)\n",
    "- OPP_FB% (First Blood Rate do Time Vermelho)\n",
    "- OPP_FT% (First Blood Rate do Time Vermelho)\n",
    "- OPP_F3T% (First To Three Towers Rate do Time Vermelho)\n",
    "- OPP_HLD% (Harold Rate do Time Vermelho)\n",
    "- OPP_DRG% (Dragon Rate do Time Vermelho)\n",
    "- OPP_BN% (First Blood Rate do Time Vermelho)\n",
    "- OPP_LNE% (Lane Control Rate do Time Vermelho)\n",
    "- OPP_JNG% (Jungle Control Rate do Time Vermelho)\n",
    "\n",
    "Iremos excluir, portanto, as colunas:\n",
    "\n",
    "- golddiffat15 (Diferença de gold entre os times aos 15 minutos)\n",
    "- xpdiffat15 (Diferença de XP entre os times aos 15 minutos)\n",
    "- csdiffat15 (Diferença de creeps entre os times aos 15 minutos)\n",
    "- killsdiffat15 (Diferença de kills entre os times aos 15 minutos)\n",
    "- assistsdiffat15 (Diferença de assists entre os times aos 15 minutos)\n",
    "- golddiffat10 (Diferença de gold entre os times aos 10 minutos)\n",
    "- xpdiffat10 (Diferença de xp entre os times aos 10 minutos)\n",
    "- csdiffat10 (Diferença de creeps entre os times aos 10 minutos)\n",
    "- killsdiffat10 (Diferença de kills entre os times aos 10 minutos)\n",
    "- assistsdiffat10 (Diferença de assists entre os times aos 10 minutos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b090e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarte do identificador da partida\n",
    "data = data.drop(columns=['id'])\n",
    "# Descarte de colunas que não serão utilizadas\n",
    "data = data.drop(columns= ['golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsdiffat15', 'assistsdiffat15', 'golddiffat10', 'xpdiffat10', 'csdiffat10', 'killsdiffat10', 'assistsdiffat10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e601dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = data.columns.drop('result')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "X = data.drop(columns=['result'])\n",
    "y = data['result']\n",
    "\n",
    "# Vai armazenar os resultados dos classfiicadores (quando forem executados)\n",
    "resultados = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00819d34",
   "metadata": {},
   "source": [
    "## Implementação do Hetergeneos Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HeterogeneousBoosting(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_models = [\n",
    "            GaussianNB(),  \n",
    "            DecisionTreeClassifier(random_state=13),  \n",
    "            MLPClassifier(random_state=13),  \n",
    "            KNeighborsClassifier()  \n",
    "        ]\n",
    "        self.trained_models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "         n_samples = X.shape[0]\n",
    "         self.most_frequent_class = mode(y, keepdims=True).mode[0]\n",
    "         sample_weights = np.ones(n_samples, dtype=float)\n",
    "         self.trained_models = []\n",
    " \n",
    "         for i in range(self.n_estimators):\n",
    "             indices = np.random.choice(\n",
    "                 np.arange(n_samples),\n",
    "                 size=n_samples, \n",
    "                 replace=True,\n",
    "                 p=sample_weights / sample_weights.sum()\n",
    "             )\n",
    "             X_resampled = X.iloc[indices]\n",
    "             y_resampled = y.iloc[indices]\n",
    "\n",
    "             best_model = None\n",
    "             best_accuracy = -1\n",
    "             best_model_index = None\n",
    " \n",
    "             for idx, base_model in enumerate(self.base_models):\n",
    "                 model = clone(base_model)\n",
    "                 model.fit(X_resampled, y_resampled)\n",
    "                 y_pred = model.predict(X_resampled)\n",
    " \n",
    "                 accuracy = (y_pred == y_resampled).mean()\n",
    " \n",
    "                 if (accuracy > best_accuracy) or (\n",
    "                     accuracy == best_accuracy and self._prefer(idx, best_model_index)\n",
    "                 ):\n",
    "                     best_model = model\n",
    "                     best_accuracy = accuracy\n",
    "                     best_model_index = idx\n",
    "\n",
    "             # print(f\"Iteração {i+1}/{self.n_estimators}: Melhor modelo = {type(best_model).__name__}, Acurácia = {best_accuracy:.4f}\")\n",
    "             y_pred_full = best_model.predict(X)\n",
    "             incorrect_mask = (y_pred_full != y)\n",
    " \n",
    "             \n",
    "             sample_weights[incorrect_mask] *= 2\n",
    "\n",
    "             self.trained_models.append(best_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _prefer(self, idx1, idx2):\n",
    "        # Preferência: MLP (2) > DT (1) > KNN (3) > NB (0)\n",
    "        preference = [0, 1, 2, 3]\n",
    "        if idx2 is None:\n",
    "            return True\n",
    "        return preference[idx1] > preference[idx2]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        all_preds = np.vstack([model.predict(X) for model in self.trained_models])\n",
    "\n",
    "        final_preds = []\n",
    "        for i in range(n_samples):\n",
    "            \n",
    "            votes = all_preds[:, i]\n",
    "            vote_counts = Counter(votes)\n",
    "            max_votes = max(vote_counts.values())\n",
    "    \n",
    "            \n",
    "            most_voted_classes = [cls for cls, count in vote_counts.items() if count == max_votes]\n",
    "    \n",
    "            if len(most_voted_classes) == 1:\n",
    "                final_preds.append(most_voted_classes[0])\n",
    "            else:\n",
    "                \n",
    "                if self.most_frequent_class in most_voted_classes:\n",
    "                    final_preds.append(self.most_frequent_class)\n",
    "                else:\n",
    "                    \n",
    "                    final_preds.append(most_voted_classes[0])\n",
    "        \n",
    "        return np.array(final_preds)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_preds = []\n",
    "        for model in self.trained_models:\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                proba_preds.append(model.predict_proba(X))\n",
    "        if proba_preds:\n",
    "            return np.mean(proba_preds, axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"Nenhum modelo no ensemble suporta `predict_proba`.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae0033",
   "metadata": {},
   "source": [
    "## Função de treino-teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daab32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X, y):\n",
    "    \"\"\"\n",
    "    Treina e avalia o modelo usando validação cruzada com barra de progresso.\n",
    "    \"\"\"\n",
    "    if model == \"DT\":\n",
    "        model = DecisionTreeClassifier(random_state=13)\n",
    "        param_grid = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [5, 10, 15, 25]\n",
    "        }\n",
    "    elif model == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "        param_grid = {\n",
    "            'n_neighbors':[1,3,5,7,9]\n",
    "        }\n",
    "    elif model == \"MLP\":\n",
    "        model = MLPClassifier(random_state=13)\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(100,),(10,)],\n",
    "            'alpha': [0.0001, 0.005],\n",
    "            'learning_rate': ['constant','adaptive']\n",
    "        }\n",
    "    elif model == \"RF\":\n",
    "        model = RandomForestClassifier(random_state=13)\n",
    "        param_grid = {\n",
    "            'n_estimators': [5, 10, 15, 25],\n",
    "            'max_depth': [10, None]\n",
    "        }\n",
    "    elif model == \"HB\":\n",
    "        model = HeterogeneousBoosting()\n",
    "        param_grid = {\n",
    "            'n_estimators': [5, 10, 15, 25, 50]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo '{model}' não reconhecido.\")\n",
    "\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36854321)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in tqdm(outer_cv.split(X, y), total=outer_cv.get_n_splits(), desc=f\"Validando {model.__class__.__name__}\"):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=4)\n",
    "        grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        scores.append(acc)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55e0fe",
   "metadata": {},
   "source": [
    "## Funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5804aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_corrigido_nadeau_bengio(data1, data2, X, n_folds_externos):\n",
    "    \"\"\"\n",
    "    Parâmetros:\n",
    "    data1, data2: listas ou arrays com as acurácias\n",
    "\n",
    "    X: conjunto de dados original\n",
    "    n_folds_externos: número de folds no loop externo\n",
    "    Retorna:\n",
    "    t_stat: valor da estatística t\n",
    "    p_valor: valor-p do teste bilateral\n",
    "    \"\"\"\n",
    "    N = len(X) # número total de amostras no dataset\n",
    "    n = len(data1) # número de execuções\n",
    "    # Tamanhos dos conjuntos de treino/teste em cada fold externo\n",
    "    n_test = N // n_folds_externos\n",
    "    n_train = N - n_test\n",
    "    # Cálculo da estatística t com correção\n",
    "    diffs = np.array(data1) - np.array(data2)\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, ddof=1)\n",
    "    se_corrigido = std_diff * np.sqrt(1/n + n_test/n_train)\n",
    "    t_stat = mean_diff / se_corrigido\n",
    "    p_valor = 2 * (1 - t.cdf(abs(t_stat), df=n - 1))\n",
    "    return t_stat, p_valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8817d8",
   "metadata": {},
   "source": [
    "## Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0057650",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_and_evaluate_model(\"DT\", X, y)\n",
    "\n",
    "print(f\"Acurácias: {scores}\")\n",
    "print(f\"Média: {np.mean(scores):.3f}, Desvio padrão: {np.std(scores):.3f}\")\n",
    "\n",
    "resultados[\"DT\"] = scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8f280",
   "metadata": {},
   "source": [
    "## K Nearnest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_and_evaluate_model(\"KNN\", X, y)\n",
    "\n",
    "print(f\"Acurácias: {scores}\")\n",
    "print(f\"Média: {np.mean(scores):.3f}, Desvio padrão: {np.std(scores):.3f}\")\n",
    "\n",
    "resultados[\"KNN\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b29acd",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_and_evaluate_model(\"MLP\", X, y)\n",
    "\n",
    "print(f\"Acurácias: {scores}\")\n",
    "print(f\"Média: {np.mean(scores):.3f}, Desvio padrão: {np.std(scores):.3f}\")\n",
    "\n",
    "resultados[\"MLP\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0f73d",
   "metadata": {},
   "source": [
    "## Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea379530",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_and_evaluate_model(\"RF\", X, y)\n",
    "\n",
    "print(f\"Acurácias: {scores}\")\n",
    "print(f\"Média: {np.mean(scores):.3f}, Desvio padrão: {np.std(scores):.3f}\")\n",
    "\n",
    "resultados[\"RF\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82120aa1",
   "metadata": {},
   "source": [
    "## Heterogeneous Boosting (HB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e936db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_and_evaluate_model(\"HB\", X, y)\n",
    "\n",
    "print(f\"Acurácias: {scores}\")\n",
    "print(f\"Média: {np.mean(scores):.3f}, Desvio padrão: {np.std(scores):.3f}\")\n",
    "\n",
    "resultados[\"HB\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605611af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calcular_ic95(scores):\n",
    "    mean = np.mean(scores)\n",
    "    std = np.std(scores, ddof=1)\n",
    "    n = len(scores)\n",
    "    conf = 0.95\n",
    "    h = t.ppf((1 + conf) / 2, df=n - 1) * std / np.sqrt(n)\n",
    "    return mean, std, mean - h, mean + h\n",
    "\n",
    "tabela = []\n",
    "\n",
    "for metodo, scores in resultados.items():\n",
    "    media, desvio, inf, sup = calcular_ic95(scores)\n",
    "    tabela.append([metodo, round(media, 3), round(desvio, 3), round(inf, 3), round(sup, 3)])\n",
    "df_tabela = pd.DataFrame(tabela, columns=['Método', 'Média', 'Desvio Padrão', 'IC 95% Inferior', 'IC 95% Superior'])\n",
    "df_tabela.set_index('Método', inplace=True)\n",
    "df_tabela.index.name = None  \n",
    "display(df_tabela)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_long = pd.DataFrame([\n",
    "    {'Método': metodo, 'Acurácia': acc}\n",
    "    for metodo, scores in resultados.items()\n",
    "    for acc in scores\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(data=df_long, x='Método', y='Acurácia')\n",
    "plt.title(\"Boxplot das Acurácias por Método\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba514c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metodos = list(resultados.keys())\n",
    "n = len(metodos)\n",
    "matriz = pd.DataFrame(\"\", index=metodos, columns=metodos)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        scores1 = resultados[metodos[i]]\n",
    "        scores2 = resultados[metodos[j]]\n",
    "        if i < j:\n",
    "            stat, p = t_corrigido_nadeau_bengio(scores1, scores2, X, 10)\n",
    "        else:\n",
    "            \n",
    "            stat, p = stats.wilcoxon(scores1, scores2)\n",
    "        # Se p < 0.001, exibe 0.001\n",
    "        p_show = 0.001 if p < 0.001 else p\n",
    "        txt = f\"**{p_show:.3f}**\" if p < 0.05 else f\"{p_show:.3f}\"\n",
    "        matriz.iloc[i, j] = txt\n",
    "\n",
    "print(\"\\nMatriz de Testes de Hipóteses (p-valores):\")\n",
    "display(matriz)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
